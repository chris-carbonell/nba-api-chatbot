{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a0d8dcd-dcf3-429d-896c-0f82c558a764",
   "metadata": {},
   "source": [
    "# Overview\n",
    "* https://keras.io/examples/nlp/ner_transformers/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9becc1da-dde8-4b55-983c-70c5d01611cd",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81ef1057-f040-4441-b83d-13fc34688422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "\n",
    "# data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ml\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from conlleval import evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311d09a2-d375-4157-983e-baf0d95e8fd2",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf8e55d5-5292-4e62-a78b-03aecc9e660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CSV = \"../nba_api_chatbot/data/questions.csv\"\n",
    "PATH_TXT = \"../nba_api_chatbot/data/questions.txt\"\n",
    "PATH_VOCABULARY = \"../nba_api_chatbot/data/vocabulary.txt\"\n",
    "\n",
    "PATH_MODEL = \"../nba_api_chatbot/models/ner\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013fe61-4102-4e74-a2c7-bc7afb27c4a4",
   "metadata": {},
   "source": [
    "# Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55556c9-9e14-498a-b93f-e28c4f14648b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.ffn = keras.Sequential(\n",
    "            [\n",
    "                keras.layers.Dense(ff_dim, activation=\"relu\"),\n",
    "                keras.layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm1 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = keras.layers.Dropout(rate)\n",
    "        self.dropout2 = keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cb95ef5-4338-42d5-9046-f944e4eb7bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.pos_emb = keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        maxlen = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        position_embeddings = self.pos_emb(positions)\n",
    "        token_embeddings = self.token_emb(inputs)\n",
    "        return token_embeddings + position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd658b49-964e-48b6-9e7a-b65e522c82d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERModel(keras.Model):\n",
    "    def __init__(\n",
    "        self, num_tags, vocab_size, maxlen=128, embed_dim=32, num_heads=2, ff_dim=32\n",
    "    ):\n",
    "        super(NERModel, self).__init__()\n",
    "        self.embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "        self.transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "        self.dropout1 = layers.Dropout(0.1)\n",
    "        self.ff = layers.Dense(ff_dim, activation=\"relu\")\n",
    "        self.dropout2 = layers.Dropout(0.1)\n",
    "        self.ff_final = layers.Dense(num_tags, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.transformer_block(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        x = self.ff_final(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc67dae-352b-44c3-acfc-707c2b42b6d4",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da28e532-b664-4137-b1c8-3ac59a949c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll_data = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18f40a21-5197-4dbb-8df5-dd4b5a130144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conll_data['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b471155-de92-4936-97e7-485bf8b62509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def export_to_file(export_file_path, data):\n",
    "#     with open(export_file_path, \"w\") as f:\n",
    "#         for record in data:\n",
    "#             ner_tags = record[\"ner_tags\"]\n",
    "#             tokens = record[\"tokens\"]\n",
    "#             if len(tokens) > 0:\n",
    "#                 f.write(\n",
    "#                     str(len(tokens))\n",
    "#                     + \"\\t\"\n",
    "#                     + \"\\t\".join(tokens)\n",
    "#                     + \"\\t\"\n",
    "#                     + \"\\t\".join(map(str, ner_tags))\n",
    "#                     + \"\\n\"\n",
    "#                 )\n",
    "\n",
    "# os.mkdir(\"data\")\n",
    "# export_to_file(\"./data/conll_train.txt\", conll_data[\"train\"])\n",
    "# export_to_file(\"./data/conll_val.txt\", conll_data[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f195c4e-ae0a-4705-8a33-dfab2eabce90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>player_full_name</th>\n",
       "      <th>stat_col</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how many GP did Alaa Abdelnaby have</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>GP</td>\n",
       "      <td>['how', 'many', 'GP', 'did', 'Alaa', 'Abdelnab...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>how many GP does Alaa Abdelnaby have</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>GP</td>\n",
       "      <td>['how', 'many', 'GP', 'does', 'Alaa', 'Abdelna...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>how many games played did Alaa Abdelnaby have</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>GP</td>\n",
       "      <td>['how', 'many', 'games', 'played', 'did', 'Ala...</td>\n",
       "      <td>[1, 1, 4, 5, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>how many games played does Alaa Abdelnaby have</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>GP</td>\n",
       "      <td>['how', 'many', 'games', 'played', 'does', 'Al...</td>\n",
       "      <td>[1, 1, 4, 5, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>how many games did Alaa Abdelnaby have</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>GP</td>\n",
       "      <td>['how', 'many', 'games', 'did', 'Alaa', 'Abdel...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048501</th>\n",
       "      <td>how many PT does Matt Zunic have</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>PTS</td>\n",
       "      <td>['how', 'many', 'PT', 'does', 'Matt', 'Zunic',...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048502</th>\n",
       "      <td>how many points did Matt Zunic have</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>PTS</td>\n",
       "      <td>['how', 'many', 'points', 'did', 'Matt', 'Zuni...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048503</th>\n",
       "      <td>how many points does Matt Zunic have</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>PTS</td>\n",
       "      <td>['how', 'many', 'points', 'does', 'Matt', 'Zun...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048504</th>\n",
       "      <td>how many point did Matt Zunic have</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>PTS</td>\n",
       "      <td>['how', 'many', 'point', 'did', 'Matt', 'Zunic...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048505</th>\n",
       "      <td>how many point does Matt Zunic have</td>\n",
       "      <td>Matt Zunic</td>\n",
       "      <td>PTS</td>\n",
       "      <td>['how', 'many', 'point', 'does', 'Matt', 'Zuni...</td>\n",
       "      <td>[1, 1, 4, 1, 2, 3, 1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1048506 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question player_full_name  \\\n",
       "0                   how many GP did Alaa Abdelnaby have   Alaa Abdelnaby   \n",
       "1                  how many GP does Alaa Abdelnaby have   Alaa Abdelnaby   \n",
       "2         how many games played did Alaa Abdelnaby have   Alaa Abdelnaby   \n",
       "3        how many games played does Alaa Abdelnaby have   Alaa Abdelnaby   \n",
       "4                how many games did Alaa Abdelnaby have   Alaa Abdelnaby   \n",
       "...                                                 ...              ...   \n",
       "1048501                how many PT does Matt Zunic have       Matt Zunic   \n",
       "1048502             how many points did Matt Zunic have       Matt Zunic   \n",
       "1048503            how many points does Matt Zunic have       Matt Zunic   \n",
       "1048504              how many point did Matt Zunic have       Matt Zunic   \n",
       "1048505             how many point does Matt Zunic have       Matt Zunic   \n",
       "\n",
       "        stat_col                                             tokens  \\\n",
       "0             GP  ['how', 'many', 'GP', 'did', 'Alaa', 'Abdelnab...   \n",
       "1             GP  ['how', 'many', 'GP', 'does', 'Alaa', 'Abdelna...   \n",
       "2             GP  ['how', 'many', 'games', 'played', 'did', 'Ala...   \n",
       "3             GP  ['how', 'many', 'games', 'played', 'does', 'Al...   \n",
       "4             GP  ['how', 'many', 'games', 'did', 'Alaa', 'Abdel...   \n",
       "...          ...                                                ...   \n",
       "1048501      PTS  ['how', 'many', 'PT', 'does', 'Matt', 'Zunic',...   \n",
       "1048502      PTS  ['how', 'many', 'points', 'did', 'Matt', 'Zuni...   \n",
       "1048503      PTS  ['how', 'many', 'points', 'does', 'Matt', 'Zun...   \n",
       "1048504      PTS  ['how', 'many', 'point', 'did', 'Matt', 'Zunic...   \n",
       "1048505      PTS  ['how', 'many', 'point', 'does', 'Matt', 'Zuni...   \n",
       "\n",
       "                         ner_tags  \n",
       "0           [1, 1, 4, 1, 2, 3, 1]  \n",
       "1           [1, 1, 4, 1, 2, 3, 1]  \n",
       "2        [1, 1, 4, 5, 1, 2, 3, 1]  \n",
       "3        [1, 1, 4, 5, 1, 2, 3, 1]  \n",
       "4           [1, 1, 4, 1, 2, 3, 1]  \n",
       "...                           ...  \n",
       "1048501     [1, 1, 4, 1, 2, 3, 1]  \n",
       "1048502     [1, 1, 4, 1, 2, 3, 1]  \n",
       "1048503     [1, 1, 4, 1, 2, 3, 1]  \n",
       "1048504     [1, 1, 4, 1, 2, 3, 1]  \n",
       "1048505     [1, 1, 4, 1, 2, 3, 1]  \n",
       "\n",
       "[1048506 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = pd.read_csv(PATH_CSV, header=None)\n",
    "questions.columns = [\"question\", \"player_full_name\", \"stat_col\", \"tokens\", \"ner_tags\"]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81443f08-9a85-494b-b46f-df7faebd1214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '[PAD]', 1: 'O', 2: 'B-PLAYER', 3: 'I-PLAYER', 4: 'B-STAT', 5: 'I-STAT'}\n"
     ]
    }
   ],
   "source": [
    "def make_tag_lookup_table():\n",
    "    iob_labels = [\"B\", \"I\"]\n",
    "    # ner_labels = [\"PER\", \"ORG\", \"LOC\", \"MISC\"]\n",
    "    ner_labels = [\"PLAYER\", \"STAT\"]\n",
    "    all_labels = [(label1, label2) for label2 in ner_labels for label1 in iob_labels]\n",
    "    all_labels = [\"-\".join([a, b]) for a, b in all_labels]\n",
    "    # all_labels = [\"[PAD]\", \"O\"] + all_labels\n",
    "    all_labels = [\"[PAD]\", \"O\"] + all_labels\n",
    "    return dict(zip(range(0, len(all_labels) + 1), all_labels))\n",
    "\n",
    "\n",
    "mapping = make_tag_lookup_table()\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b589c0fe-91be-46ab-bebe-016191e4f26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_list(text, type = str):\n",
    "    if type == str:\n",
    "        return [x[1:-1] for x in text.strip(\"[]\").split(\", \")]\n",
    "    elif type == int:\n",
    "        return [int(x) for x in text.strip(\"[]\").split(\", \")]\n",
    "    else:\n",
    "        raise Exception(f\"type not supported: {str(type)}\")\n",
    "\n",
    "questions['tokens_parsed'] = questions.apply(lambda x: convert_text_to_list(x['tokens']), axis=1)\n",
    "questions['ner_tags_parsed'] = questions.apply(lambda x: convert_text_to_list(x['ner_tags'], type=int), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0effe3-7e6d-4258-844b-27a25542185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_tokens = sum(conll_data[\"train\"][\"tokens\"], [])\n",
    "# all_tokens = sum(tokens, [])\n",
    "all_tokens = [token for question in questions['tokens_parsed'].tolist() for token in question]\n",
    "all_tokens_array = np.array(list(map(str.lower, all_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d0b2d85-2bee-42ff-9ca2-6eb21b3a2ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = [tag for ner_tags in questions['ner_tags_parsed'].tolist() for tag in ner_tags]\n",
    "all_tags_array = np.array(list(all_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cedc2724-fd2e-4878-a244-5b206b0404df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_tags_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c92a98-3541-4364-9aa0-d1c85179e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4221\n"
     ]
    }
   ],
   "source": [
    "# all_tokens = sum(conll_data[\"train\"][\"tokens\"], [])\n",
    "# all_tokens_array = np.array(list(map(str.lower, all_tokens)))\n",
    "\n",
    "counter = Counter(all_tokens_array)\n",
    "print(len(counter))\n",
    "\n",
    "num_tags = len(mapping)\n",
    "vocab_size = 20000\n",
    "\n",
    "# We only take (vocab_size - 2) most commons words from the training data since\n",
    "# the `StringLookup` class uses 2 additional tokens - one denoting an unknown\n",
    "# token and another one denoting a masking token\n",
    "vocabulary = [token for token, count in counter.most_common(vocab_size - 2)]\n",
    "\n",
    "# The StringLook class will convert tokens to token IDs\n",
    "lookup_layer = keras.layers.StringLookup(\n",
    "    vocabulary=vocabulary\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94a0ffc9-0857-4db2-88e1-6cd6290ee6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vocabulary\n",
    "with open(PATH_VOCABULARY, 'w') as f:\n",
    "    for item in vocabulary:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1af890-b44c-4c36-8c65-0817eceac0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"how many field goals did michael jordan have\"\n",
    "# tokens = text.split(\" \")\n",
    "# lookup_layer(tf.strings.lower(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c2c9dd9-09a9-4aaa-b7c0-e97c4009e636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048506"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = tf.data.TextLineDataset(PATH_TXT)\n",
    "num_lines = sum(1 for line in open(PATH_TXT))\n",
    "num_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "642f906b-6d18-4b8a-864d-c973688aa1ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'7\\thow\\tmany\\tGP\\tdid\\tAlaa\\tAbdelnaby\\thave\\t1\\t1\\t4\\t1\\t2\\t3\\t1']\n"
     ]
    }
   ],
   "source": [
    "print(list(all_data.take(1).as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a7a521d-d3d0-40de-b9f0-e081a4a28a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-split-a-tensorflow-dataset-into-train-validation-and-test-sets-526c8dd29438\n",
    "def get_dataset_partitions_tf(ds, ds_size, train_split=0.8, test_split=0.2, shuffle=True, shuffle_size=10000):\n",
    "    \n",
    "    assert (train_split + test_split) == 1\n",
    "    \n",
    "    if shuffle:\n",
    "        # Specify seed to always have the same split distribution between runs\n",
    "        ds = ds.shuffle(shuffle_size, seed=12)\n",
    "    \n",
    "    train_size = int(train_split * ds_size)\n",
    "    \n",
    "    train_ds = ds.take(train_size)\n",
    "    test_ds = ds.skip(train_size)\n",
    "    \n",
    "    return train_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62137f31-da2b-4651-9841-901941291509",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = get_dataset_partitions_tf(all_data, num_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4065195-f991-4147-a909-3691e4633641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_record_to_training_data(record):\n",
    "    record = tf.strings.split(record, sep=\"\\t\")\n",
    "    length = tf.strings.to_number(record[0], out_type=tf.int32)\n",
    "    tokens = record[1 : length + 1]\n",
    "    tags = record[length + 1 :]\n",
    "    tags = tf.strings.to_number(tags, out_type=tf.int64)\n",
    "    # tags += 1\n",
    "    return tokens, tags\n",
    "\n",
    "\n",
    "def lowercase_and_convert_to_ids(tokens):\n",
    "    tokens = tf.strings.lower(tokens)\n",
    "    return lookup_layer(tokens)\n",
    "\n",
    "\n",
    "# We use `padded_batch` here because each record in the dataset has a\n",
    "# different length.\n",
    "batch_size = 32\n",
    "train_dataset = (\n",
    "    train_data.map(map_record_to_training_data)\n",
    "    .map(lambda x, y: (lowercase_and_convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")\n",
    "test_dataset = (\n",
    "    test_data.map(map_record_to_training_data)\n",
    "    .map(lambda x, y: (lowercase_and_convert_to_ids(x), y))\n",
    "    .padded_batch(batch_size)\n",
    ")\n",
    "\n",
    "ner_model = NERModel(num_tags, vocab_size, embed_dim=32, num_heads=4, ff_dim=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d0d4e3d8-494c-4396-a709-329f0b72795f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomNonPaddingTokenLoss(keras.losses.Loss):\n",
    "    def __init__(self, name=\"custom_ner_loss\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        loss_fn = keras.losses.SparseCategoricalCrossentropy(\n",
    "            from_logits=True, reduction=keras.losses.Reduction.NONE\n",
    "        )\n",
    "        loss = loss_fn(y_true, y_pred)\n",
    "        mask = tf.cast((y_true > 0), dtype=tf.float32)\n",
    "        loss = loss * mask\n",
    "        return tf.reduce_sum(loss) / tf.reduce_sum(mask)\n",
    "\n",
    "\n",
    "loss = CustomNonPaddingTokenLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd43bf74-06ce-4251-90b8-322576f4ead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carbo\\Desktop\\nba-api-chatbot\\venv-nba-api-chatbot\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26213/26213 [==============================] - 433s 16ms/step - loss: 0.0014\n",
      "Epoch 2/10\n",
      "26213/26213 [==============================] - 483s 18ms/step - loss: 1.0250e-05\n",
      "Epoch 3/10\n",
      "26213/26213 [==============================] - 667s 25ms/step - loss: 9.0545e-06\n",
      "Epoch 4/10\n",
      "26213/26213 [==============================] - 1516s 58ms/step - loss: 1.6021e-05\n",
      "Epoch 5/10\n",
      "26213/26213 [==============================] - 644s 25ms/step - loss: 3.6754e-05\n",
      "Epoch 6/10\n",
      "26213/26213 [==============================] - 440s 17ms/step - loss: 1.1163e-09\n",
      "Epoch 7/10\n",
      "26213/26213 [==============================] - 409s 16ms/step - loss: 1.1656e-05\n",
      "Epoch 8/10\n",
      "26213/26213 [==============================] - 408s 16ms/step - loss: 6.5396e-10\n",
      "Epoch 9/10\n",
      "26213/26213 [==============================] - 408s 16ms/step - loss: 1.4966e-10\n",
      "Epoch 10/10\n",
      "26213/26213 [==============================] - 406s 15ms/step - loss: 4.4810e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a4d1813130>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_model.compile(optimizer=\"adam\", loss=loss)\n",
    "ner_model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e01fd32-09d3-4e7e-8431-29dcf1a3936d",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "830b6cef-b4c9-4b06-b97c-76966938f9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  1   2  19  23   4  90 108   3]], shape=(1, 8), dtype=int64)\n",
      "['O', 'O', 'B-STAT', 'I-STAT', 'O', 'B-PLAYER', 'I-PLAYER', 'O']\n"
     ]
    }
   ],
   "source": [
    "def tokenize_and_convert_to_ids(text):\n",
    "    tokens = text.split()\n",
    "    return lowercase_and_convert_to_ids(tokens)\n",
    "\n",
    "\n",
    "# Sample inference using the trained model\n",
    "sample_input = tokenize_and_convert_to_ids(\n",
    "    \"how many field goals did michael jordan have\"\n",
    ")\n",
    "sample_input = tf.reshape(sample_input, shape=[1, -1])\n",
    "print(sample_input)\n",
    "\n",
    "output = ner_model.predict(sample_input)\n",
    "prediction = np.argmax(output, axis=-1)[0]\n",
    "prediction = [mapping[i] for i in prediction]\n",
    "\n",
    "# eu -> B-ORG, german -> B-MISC, british -> B-MISC\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9abc4075-aff5-42e5-916c-34e6aa3933f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '[PAD]', 1: 'O', 2: 'B-PLAYER', 3: 'I-PLAYER', 4: 'B-STAT', 5: 'I-STAT'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ae1e7c-b0e4-44a8-a092-8c7b6dfb44c6",
   "metadata": {},
   "source": [
    "# Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2f61be3-7cd1-4d27-8a62-d5871af1fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ner_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " token_and_position_embeddin  multiple                 644096    \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_block (Transfor  multiple                 21120     \n",
      " merBlock)                                                       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             multiple                  2112      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         multiple                  0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             multiple                  390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 667,718\n",
      "Trainable params: 667,718\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ner_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dec6e8-9cc0-4e39-93dc-2ce9387cecf2",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7fbc4760-389d-4b9c-886b-2a98eb5245e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, embedding_1_layer_call_fn, embedding_1_layer_call_and_return_conditional_losses, multi_head_attention_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../nba-api-chatbot/models/ner\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../nba-api-chatbot/models/ner\\assets\n"
     ]
    }
   ],
   "source": [
    "ner_model.save(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6974f1-dd7e-4c34-9454-787772428c14",
   "metadata": {},
   "source": [
    "# Calculate Metrics\n",
    "* from conlleval import evaluate\n",
    "    * did not work for me\n",
    "* so I pulled the essential funcs from:<br>\n",
    "https://github.com/sighsmile/conlleval/blob/master/conlleval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50c17501-faf3-4dae-b14c-b5e5e8f70c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_tag_ids, all_predicted_tag_ids = [], []\n",
    "\n",
    "for x, y in test_dataset:\n",
    "    \n",
    "    output = ner_model.predict(x)\n",
    "    predictions = np.argmax(output, axis=-1)\n",
    "    predictions = np.reshape(predictions, [-1])\n",
    "\n",
    "    true_tag_ids = np.reshape(y, [-1])\n",
    "\n",
    "    mask = (true_tag_ids > 0) & (predictions > 0)\n",
    "    true_tag_ids = true_tag_ids[mask]\n",
    "    predicted_tag_ids = predictions[mask]\n",
    "\n",
    "    all_true_tag_ids.append(true_tag_ids)\n",
    "    all_predicted_tag_ids.append(predicted_tag_ids)\n",
    "\n",
    "all_true_tag_ids = np.concatenate(all_true_tag_ids)\n",
    "all_predicted_tag_ids = np.concatenate(all_predicted_tag_ids)\n",
    "\n",
    "predicted_tags = [mapping[tag] for tag in all_predicted_tag_ids]\n",
    "real_tags = [mapping[tag] for tag in all_true_tag_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f9a2c4-dbf4-4d9b-91f5-e1dfe4c432c8",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae4b987f-bc0e-48f4-a168-d45768da0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate(real_tags, predicted_tags, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "433f0a67-d3ba-4247-9ee2-97be6c9bcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "true_seqs = real_tags\n",
    "pred_seqs = predicted_tags\n",
    "\n",
    "def is_chunk_start(prev_tag, tag):\n",
    "    \"\"\"\n",
    "    check if a new chunk started between the previous and current word\n",
    "    \"\"\"\n",
    "    prefix1, chunk_type1 = split_tag(prev_tag)\n",
    "    prefix2, chunk_type2 = split_tag(tag)\n",
    "\n",
    "    if prefix2 == 'O':\n",
    "        return False\n",
    "    if prefix1 == 'O':\n",
    "        return prefix2 != 'O'\n",
    "\n",
    "    if chunk_type1 != chunk_type2:\n",
    "        return True\n",
    "\n",
    "    return prefix2 in ['B', 'S'] or prefix1 in ['E', 'S']\n",
    "\n",
    "def is_chunk_end(prev_tag, tag):\n",
    "    \"\"\"\n",
    "    check if the previous chunk ended between the previous and current word\n",
    "    e.g. \n",
    "    (B-PER, I-PER) -> False\n",
    "    (B-LOC, O)  -> True\n",
    "    Note: in case of contradicting tags, e.g. (B-PER, I-LOC)\n",
    "    this is considered as (B-PER, B-LOC)\n",
    "    \"\"\"\n",
    "    prefix1, chunk_type1 = split_tag(prev_tag)\n",
    "    prefix2, chunk_type2 = split_tag(tag)\n",
    "\n",
    "    if prefix1 == 'O':\n",
    "        return False\n",
    "    if prefix2 == 'O':\n",
    "        return prefix1 != 'O'\n",
    "\n",
    "    if chunk_type1 != chunk_type2:\n",
    "        return True\n",
    "\n",
    "    return prefix2 in ['B', 'S'] or prefix1 in ['E', 'S']\n",
    "\n",
    "def split_tag(chunk_tag):\n",
    "    \"\"\"\n",
    "    split chunk tag into IOBES prefix and chunk_type\n",
    "    e.g. \n",
    "    B-PER -> (B, PER)\n",
    "    O -> (O, None)\n",
    "    \"\"\"\n",
    "    if chunk_tag == 'O':\n",
    "        return ('O', None)\n",
    "    return chunk_tag.split('-', maxsplit=1)\n",
    "\n",
    "def count_chunks(true_seqs, pred_seqs):\n",
    "    \"\"\"\n",
    "    true_seqs: a list of true tags\n",
    "    pred_seqs: a list of predicted tags\n",
    "    return: \n",
    "    correct_chunks: a dict (counter), \n",
    "                    key = chunk types, \n",
    "                    value = number of correctly identified chunks per type\n",
    "    true_chunks:    a dict, number of true chunks per type\n",
    "    pred_chunks:    a dict, number of identified chunks per type\n",
    "    correct_counts, true_counts, pred_counts: similar to above, but for tags\n",
    "    \"\"\"\n",
    "    correct_chunks = defaultdict(int)\n",
    "    true_chunks = defaultdict(int)\n",
    "    pred_chunks = defaultdict(int)\n",
    "\n",
    "    correct_counts = defaultdict(int)\n",
    "    true_counts = defaultdict(int)\n",
    "    pred_counts = defaultdict(int)\n",
    "\n",
    "    prev_true_tag, prev_pred_tag = 'O', 'O'\n",
    "    correct_chunk = None\n",
    "\n",
    "    for true_tag, pred_tag in zip(true_seqs, pred_seqs):\n",
    "        if true_tag == pred_tag:\n",
    "            correct_counts[true_tag] += 1\n",
    "        true_counts[true_tag] += 1\n",
    "        pred_counts[pred_tag] += 1\n",
    "\n",
    "        _, true_type = split_tag(true_tag)\n",
    "        _, pred_type = split_tag(pred_tag)\n",
    "\n",
    "        if correct_chunk is not None:\n",
    "            true_end = is_chunk_end(prev_true_tag, true_tag)\n",
    "            pred_end = is_chunk_end(prev_pred_tag, pred_tag)\n",
    "\n",
    "            if pred_end and true_end:\n",
    "                correct_chunks[correct_chunk] += 1\n",
    "                correct_chunk = None\n",
    "            elif pred_end != true_end or true_type != pred_type:\n",
    "                correct_chunk = None\n",
    "\n",
    "        true_start = is_chunk_start(prev_true_tag, true_tag)\n",
    "        pred_start = is_chunk_start(prev_pred_tag, pred_tag)\n",
    "\n",
    "        if true_start and pred_start and true_type == pred_type:\n",
    "            correct_chunk = true_type\n",
    "        if true_start:\n",
    "            true_chunks[true_type] += 1\n",
    "        if pred_start:\n",
    "            pred_chunks[pred_type] += 1\n",
    "\n",
    "        prev_true_tag, prev_pred_tag = true_tag, pred_tag\n",
    "    if correct_chunk is not None:\n",
    "        correct_chunks[correct_chunk] += 1\n",
    "\n",
    "    return (correct_chunks, true_chunks, pred_chunks, \n",
    "        correct_counts, true_counts, pred_counts)\n",
    "\n",
    "(correct_chunks, true_chunks, pred_chunks, correct_counts, true_counts, pred_counts) = count_chunks(true_seqs, pred_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b5d0d8a-dd4c-422e-a9b6-de181d171622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(tp, p, t, percent=True):\n",
    "    \"\"\"\n",
    "    compute overall precision, recall and FB1 (default values are 0.0)\n",
    "    if percent is True, return 100 * original decimal value\n",
    "    \"\"\"\n",
    "    precision = tp / p if p else 0\n",
    "    recall = tp / t if t else 0\n",
    "    fb1 = 2 * precision * recall / (precision + recall) if precision + recall else 0\n",
    "    if percent:\n",
    "        return 100 * precision, 100 * recall, 100 * fb1\n",
    "    else:\n",
    "        return precision, recall, fb1\n",
    "\n",
    "def get_result(correct_chunks, true_chunks, pred_chunks,\n",
    "    correct_counts, true_counts, pred_counts, verbose=True):\n",
    "    \"\"\"\n",
    "    if verbose, print overall performance, as well as preformance per chunk type;\n",
    "    otherwise, simply return overall prec, rec, f1 scores\n",
    "    \"\"\"\n",
    "    # sum counts\n",
    "    sum_correct_chunks = sum(correct_chunks.values())\n",
    "    sum_true_chunks = sum(true_chunks.values())\n",
    "    sum_pred_chunks = sum(pred_chunks.values())\n",
    "\n",
    "    sum_correct_counts = sum(correct_counts.values())\n",
    "    sum_true_counts = sum(true_counts.values())\n",
    "\n",
    "    nonO_correct_counts = sum(v for k, v in correct_counts.items() if k != 'O')\n",
    "    nonO_true_counts = sum(v for k, v in true_counts.items() if k != 'O')\n",
    "\n",
    "    chunk_types = sorted(list(set(list(true_chunks) + list(pred_chunks))))\n",
    "\n",
    "    # compute overall precision, recall and FB1 (default values are 0.0)\n",
    "    prec, rec, f1 = calc_metrics(sum_correct_chunks, sum_pred_chunks, sum_true_chunks)\n",
    "    res = (prec, rec, f1)\n",
    "    if not verbose:\n",
    "        return res\n",
    "\n",
    "    # print overall performance, and performance per chunk type\n",
    "    \n",
    "    print(\"processed %i tokens with %i phrases; \" % (sum_true_counts, sum_true_chunks), end='')\n",
    "    print(\"found: %i phrases; correct: %i.\\n\" % (sum_pred_chunks, sum_correct_chunks), end='')\n",
    "        \n",
    "    print(\"accuracy: %6.2f%%; (non-O)\" % (100*nonO_correct_counts/nonO_true_counts))\n",
    "    print(\"accuracy: %6.2f%%; \" % (100*sum_correct_counts/sum_true_counts), end='')\n",
    "    print(\"precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f\" % (prec, rec, f1))\n",
    "\n",
    "    # for each chunk type, compute precision, recall and FB1 (default values are 0.0)\n",
    "    for t in chunk_types:\n",
    "        prec, rec, f1 = calc_metrics(correct_chunks[t], pred_chunks[t], true_chunks[t])\n",
    "        print(\"%17s: \" %t , end='')\n",
    "        print(\"precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f\" %\n",
    "                    (prec, rec, f1), end='')\n",
    "        print(\"  %d\" % pred_chunks[t])\n",
    "\n",
    "    return res\n",
    "    # you can generate LaTeX output for tables like in\n",
    "    # http://cnts.uia.ac.be/conll2003/ner/example.tex\n",
    "    # but I'm not implementing this\n",
    "    \n",
    "# result = get_result(correct_chunks, true_chunks, pred_chunks,\n",
    "#         correct_counts, true_counts, pred_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "888e1c60-bb8b-4115-90cf-2a0100bb6ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 1639707 tokens with 419404 phrases; found: 419591 phrases; correct: 419217.\n",
      "accuracy:  99.98%; (non-O)\n",
      "accuracy:  99.99%; precision:  99.91%; recall:  99.96%; FB1:  99.93\n",
      "           PLAYER: precision:  99.82%; recall:  99.91%; FB1:  99.87  209889\n",
      "             STAT: precision: 100.00%; recall: 100.00%; FB1: 100.00  209702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99.91086558100626, 99.95541291928546, 99.9331342856632)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate(true_seqs, pred_seqs, verbose=True):\n",
    "    (correct_chunks, true_chunks, pred_chunks,\n",
    "        correct_counts, true_counts, pred_counts) = count_chunks(true_seqs, pred_seqs)\n",
    "    result = get_result(correct_chunks, true_chunks, pred_chunks,\n",
    "        correct_counts, true_counts, pred_counts, verbose=verbose)\n",
    "    return result\n",
    "\n",
    "evaluate(real_tags, predicted_tags, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-nba-api-chatbot",
   "language": "python",
   "name": "venv-nba-api-chatbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
